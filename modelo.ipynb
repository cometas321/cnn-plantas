{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c243e6a",
   "metadata": {},
   "source": [
    "# Clasificador de Flores (128×128, 5 clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eafe7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Comprobar el intérprete de Python\n",
    "\n",
    "**Código asociado:** `import sys; print(sys.executable)`\n",
    "\n",
    "**Qué hace / por qué:**\n",
    "\n",
    "* Muestra la ruta del intérprete de Python que está ejecutando el Notebook (por ejemplo `/home/user/venv/bin/python`).\n",
    "* Útil para confirmar que estás usando el entorno virtual o conda correcto (evita confusiones con versiones y dependencias).\n",
    "* Si ves una ruta distinta a la esperada, activa el entorno correcto antes de ejecutar el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f1aa3",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Importar TensorFlow y constantes globales\n",
    "\n",
    "**Código asociado:** `import tensorflow as tf` y definición de `IMAGE_SIZE`, `BATCH_SIZE`, `DATA_DIR`\n",
    "\n",
    "**Qué hace / por qué:**\n",
    "\n",
    "* `import tensorflow as tf` carga TensorFlow/Keras.\n",
    "* `IMAGE_SIZE = (128,128)` define el tamaño al que se redimensionarán todas las imágenes (consistencia para la red).\n",
    "* `BATCH_SIZE = 32` controla cuántas imágenes procesa el modelo a la vez (balance entre velocidad y memoria).\n",
    "* `DATA_DIR = \"flores\"` es la carpeta raíz con subcarpetas `train/`, `val/`, `test/`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676de50",
   "metadata": {},
   "source": [
    "## 3) Carga del dataset con `image_dataset_from_directory`\n",
    "\n",
    "**Código asociado:** llamadas a `tf.keras.utils.image_dataset_from_directory(...)`\n",
    "\n",
    "**Qué hace / por qué:**\n",
    "\n",
    "* Crea `tf.data.Dataset` para `train_ds`, `val_ds`, `test_ds` desde carpetas organizadas por clase (`DATA_DIR/train/<clase>`).\n",
    "* Parámetros clave:\n",
    "\n",
    "  * `labels='inferred'`: se infieren las etiquetas a partir de los nombres de las subcarpetas.\n",
    "  * `label_mode='int'`: las etiquetas serán enteros (`0..num_classes-1`). **Usamos luego `sparse_categorical_crossentropy`.**\n",
    "  * `image_size=IMAGE_SIZE`: redimensiona las imágenes a 128×128.\n",
    "  * `batch_size=BATCH_SIZE` y `shuffle=True` (solo en entrenamiento).\n",
    "  * `seed=123` para reproducibilidad en la selección aleatoria.\n",
    "* **Salida por lote**:\n",
    "\n",
    "  * `images` → tensor `(batch_size, 128, 128, 3)`\n",
    "  * `labels` → tensor `(batch_size,)` (enteros)\n",
    "* `class_names = train_ds.class_names` lista las etiquetas ordenadas (ej. `['rosa','tulipan',...]`) y `num_classes = len(class_names)`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR = \"flores\"  # con subcarpetas train, val, test\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + '/train',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + '/val',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + '/test',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Clases:\", class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14447e51",
   "metadata": {},
   "source": [
    "## 4) Normalización / rendimiento: `cache()` y `prefetch()`\n",
    "\n",
    "**Código asociado:** `train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)` (y para val/test)\n",
    "\n",
    "**Qué hace / por qué:**\n",
    "\n",
    "* `cache()`: guarda en memoria (o en disco si se pasa un filename) los datos procesados la primera vez para acelerar épocas posteriores. **Cuidado:** si tu dataset no cabe en RAM, quita `cache()` o usa `cache('ruta_cache')`.\n",
    "* `prefetch(buffer_size=AUTOTUNE)`: prepara el siguiente lote mientras la GPU/CPU entrena el actual — reduce el tiempo de espera entre batches.\n",
    "* `AUTOTUNE` deja que TF elija el mejor comportamiento automático.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalización\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds  = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68602ea",
   "metadata": {},
   "source": [
    "## 5) Aumento de datos (Data Augmentation)\n",
    "\n",
    "**Código asociado:** `data_augmentation = tf.keras.Sequential([...layers.RandomFlip..., ...])`\n",
    "\n",
    "**Qué hace / por qué:**\n",
    "\n",
    "* Aplica transformaciones aleatorias a las imágenes durante el entrenamiento: flip, rotación, zoom, cambio de contraste, etc.\n",
    "* Mejora la capacidad de generalización del modelo al simular variaciones naturales (orientación, zoom, iluminación).\n",
    "* Estas capas implementadas como `tf.keras.layers` se ejecutan en la GPU y se aplican **solo en modo entrenamiento** cuando están dentro del modelo.\n",
    "* Ventaja: evita tener que generar y almacenar versiones aumentadas manualmente.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363dd43",
   "metadata": {},
   "source": [
    "## 6) Construcción del modelo CNN (visión general)\n",
    "\n",
    "**Código asociado:** la función `build_cnn(...)` y `model = build_cnn(...)`\n",
    "\n",
    "**Arquitectura (resumen):**\n",
    "\n",
    "1. `Input(shape=(128,128,3))`\n",
    "2. `Rescaling(1./255)` — normaliza pixeles a `[0,1]`\n",
    "3. `data_augmentation(...)` — capas de aumento\n",
    "4. **Bloque Conv 1**: `Conv2D(32, 3x3, relu, padding='same')` → `BatchNormalization()` → `MaxPooling2D(2x2)`\n",
    "5. **Bloque Conv 2**: `Conv2D(64, 3x3, relu)` → `BatchNormalization()` → `MaxPooling2D`\n",
    "6. **Bloque Conv 3**: `Conv2D(128, 3x3, relu)` → `BatchNormalization()` → `MaxPooling2D`\n",
    "7. `GlobalAveragePooling2D()` → `Dropout(dropout_rate)` → `Dense(128, relu)` → `Dropout(0.3)` → `Dense(num_classes, softmax)`\n",
    "\n",
    "**Por qué esta estructura:**\n",
    "\n",
    "* Las capas convolucionales extraen características locales (bordes → texturas → partes de objetos).\n",
    "* `BatchNormalization` estabiliza y acelera el entrenamiento normalizando las activaciones por mini-batch.\n",
    "* `MaxPooling` reduce resolución espacial (reduce parámetros, agrega invarianza a pequeñas traslaciones).\n",
    "* `GlobalAveragePooling2D` resume cada mapa de características en un valor promedio (reduce el número de parámetros comparado con `Flatten` + Dense grande).\n",
    "* `Dropout` es una técnica de regularización para evitar sobreajuste.\n",
    "* `Dense(..., softmax)` en la salida da probabilidades por clase.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40271701",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construcción del modelo CNN desde cero\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_cnn(input_shape=(128,128,3), num_classes=5, dropout_rate=0.5):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Normalización simple (0-255 -> 0-1)\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "    # Aumento de datos (solo activo en entrenamiento)\n",
    "    x = data_augmentation(x)\n",
    "\n",
    "    # Bloque Conv 1\n",
    "    x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Bloque Conv 2\n",
    "    x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Bloque Conv 3\n",
    "    x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Red densa final\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name='flower_cnn')\n",
    "    return model\n",
    "\n",
    "model = build_cnn(input_shape=(128,128,3), num_classes=num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c350f5b",
   "metadata": {},
   "source": [
    "## 7) Modelo — **detalle ampliado** (capas, formas intermedias y parámetros aproximados)\n",
    "\n",
    "> **Input**: `(None, 128, 128, 3)` — `None` = batch size variable.\n",
    "\n",
    "Paso a paso (con formas **aproximadas**):\n",
    "\n",
    "1. **Rescaling(1./255)**\n",
    "\n",
    "   * Salida: `(None, 128, 128, 3)`\n",
    "   * Parámetros: 0\n",
    "\n",
    "2. **data_augmentation(...)**\n",
    "\n",
    "   * Salida: `(None, 128, 128, 3)`\n",
    "   * Parámetros: 0 (operaciones sin pesos aprendibles)\n",
    "\n",
    "3. **Conv2D(32, 3x3, padding='same', activation='relu')**\n",
    "\n",
    "   * Salida: `(None, 128, 128, 32)`\n",
    "   * Parámetros: `(3*3*3)*32 + 32 = 896`\n",
    "\n",
    "     * fórmula: `kernel_h * kernel_w * in_channels * filters + filters(bias)`\n",
    "\n",
    "4. **BatchNormalization**\n",
    "\n",
    "   * Salida: `(None, 128, 128, 32)`\n",
    "   * Parámetros (aprendibles): `2 * 32 = 64` (gamma + beta)\n",
    "\n",
    "5. **MaxPooling2D(2x2)**\n",
    "\n",
    "   * Salida: `(None, 64, 64, 32)`\n",
    "   * Parámetros: 0\n",
    "\n",
    "6. **Conv2D(64, 3x3, relu)**\n",
    "\n",
    "   * Salida: `(None, 64, 64, 64)`\n",
    "   * Parámetros: `(3*3*32)*64 + 64 = 18,496`\n",
    "\n",
    "7. **BatchNormalization**\n",
    "\n",
    "   * Parámetros: `2 * 64 = 128`\n",
    "\n",
    "8. **MaxPooling2D**\n",
    "\n",
    "   * Salida: `(None, 32, 32, 64)`\n",
    "\n",
    "9. **Conv2D(128, 3x3, relu)**\n",
    "\n",
    "   * Salida: `(None, 32, 32, 128)`\n",
    "   * Parámetros: `(3*3*64)*128 + 128 = 73,856`\n",
    "\n",
    "10. **BatchNormalization**\n",
    "\n",
    "    * Parámetros: `2 * 128 = 256`\n",
    "\n",
    "11. **MaxPooling2D**\n",
    "\n",
    "    * Salida: `(None, 16, 16, 128)`\n",
    "\n",
    "12. **GlobalAveragePooling2D**\n",
    "\n",
    "    * Convierte `(16,16,128)` → `(128)` (promedia cada mapa de características)\n",
    "    * Parámetros: 0\n",
    "\n",
    "13. **Dropout(dropout_rate)**\n",
    "\n",
    "    * No tiene parámetros. Reduce co-adaptaciones.\n",
    "\n",
    "14. **Dense(128, activation='relu')**\n",
    "\n",
    "    * Entrada = 128 (salida del GAP)\n",
    "    * Parámetros: `128*128 + 128 = 16,512`\n",
    "\n",
    "15. **Dropout(0.3)**\n",
    "\n",
    "    * Sin parámetros.\n",
    "\n",
    "16. **Dense(num_classes=5, activation='softmax')**\n",
    "\n",
    "    * Parámetros: `128*5 + 5 = 645`\n",
    "\n",
    "**Suma aproximada de parámetros entrenables:** ~**110,853**\n",
    "(El `model.summary()` en tu ejecución mostrará el total exacto; los cálculos arriba ilustran cómo se obtienen.)\n",
    "\n",
    "**Motivos para elegir GlobalAveragePooling en vez de Flatten:**\n",
    "\n",
    "* `GAP` reduce drásticamente la cantidad de parámetros y el riesgo de overfitting.\n",
    "* Preserva la relación por canal (cada filtro → una entrada).\n",
    "* Recomendado para tareas de clasificación cuando dejamos que las últimas conv extraigan las características.\n",
    "\n",
    "**Sobre `BatchNormalization`:**\n",
    "\n",
    "* Acelera convergencia y permite utilizar tasas de aprendizaje mayores.\n",
    "* Reduce la sensibilidad a la inicialización.\n",
    "\n",
    "**Sobre `Dropout`:**\n",
    "\n",
    "* Apaga aleatoriamente unidades en entrenamiento; útil para regularizar en redes densas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb3cb6",
   "metadata": {},
   "source": [
    "## 8) Compilación y callbacks\n",
    "\n",
    "**Código asociado:** `model.compile(...)` y lista `callbacks = [...]`\n",
    "\n",
    "**Qué hace / por qué:**\n",
    "\n",
    "* `optimizer=Adam(learning_rate=1e-3)`: optimizador adaptativo, buen punto de partida.\n",
    "* `loss=SparseCategoricalCrossentropy()`: correcta cuando `label_mode='int'` (no hace falta one-hot).\n",
    "* `metrics=['accuracy']`: métrica principal para clasificación.\n",
    "* **Callbacks:**\n",
    "\n",
    "  * `ModelCheckpoint(\"best_flower_model.h5\", save_best_only=True, monitor='val_loss')`: guarda el mejor modelo según `val_loss`. Útil para restaurar la mejor versión.\n",
    "  * `EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)`: detiene el entrenamiento si `val_loss` no mejora después de `patience` épocas y restaura los pesos mejores.\n",
    "  * `ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)`: reduce la tasa de aprendizaje si el rendimiento se estanca.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_flower_model.h5\", save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46c9f2",
   "metadata": {},
   "source": [
    "Gráficos de pérdida y precisión (train vs validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de pérdida y precisión (train vs validation)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    hist = history.history\n",
    "    epochs = range(1, len(hist['loss'])+1)\n",
    "\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, hist['loss'], label='train_loss')\n",
    "    plt.plot(epochs, hist['val_loss'], label='val_loss')\n",
    "    plt.title('Pérdida')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, hist['accuracy'], label='train_acc')\n",
    "    plt.plot(epochs, hist['val_accuracy'], label='val_acc')\n",
    "    plt.title('Precisión')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Evaluación final en test set\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1866ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Matriz de confusión y reporte por clase\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Obtener etiquetas verdaderas y predichas\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Classification report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# Mostrar matriz como imagen\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "plt.yticks(range(len(class_names)), class_names)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fa4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def predict_image(model, img_path, class_names, image_size=(128,128)):\n",
    "    img = image.load_img(img_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x.astype('float32') / 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)[0]\n",
    "    top_idx = np.argmax(preds)\n",
    "    return top_idx, preds[top_idx], preds\n",
    "\n",
    "# Uso:\n",
    "idx, prob, all_probs = predict_image(model, \"probar.jpg\", class_names)\n",
    "print(class_names[idx], prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"flower_model.h5\")\n",
    "# cargar\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model(\"flower_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"flower_savedmodel\")   # carpeta con formato SavedModel\n",
    "# cargar\n",
    "model3 = tf.keras.models.load_model(\"flower_savedmodel\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
