{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMAGE_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR = \"flores\"  # con subcarpetas train, val, test\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + '/train',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + '/val',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR + '/test',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Clases:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalización\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds  = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.15),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40271701",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construcción del modelo CNN desde cero\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_cnn(input_shape=(128,128,3), num_classes=5, dropout_rate=0.5):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Normalización simple (0-255 -> 0-1)\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "    # Aumento de datos (solo activo en entrenamiento)\n",
    "    x = data_augmentation(x)\n",
    "\n",
    "    # Bloque Conv 1\n",
    "    x = layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Bloque Conv 2\n",
    "    x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Bloque Conv 3\n",
    "    x = layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Red densa final\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name='flower_cnn')\n",
    "    return model\n",
    "\n",
    "model = build_cnn(input_shape=(128,128,3), num_classes=num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69c287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compilación del modelo\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_flower_model.h5\", save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de pérdida y precisión (train vs validation)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    hist = history.history\n",
    "    epochs = range(1, len(hist['loss'])+1)\n",
    "\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, hist['loss'], label='train_loss')\n",
    "    plt.plot(epochs, hist['val_loss'], label='val_loss')\n",
    "    plt.title('Pérdida')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, hist['accuracy'], label='train_acc')\n",
    "    plt.plot(epochs, hist['val_accuracy'], label='val_acc')\n",
    "    plt.title('Precisión')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Evaluación final en test set\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1866ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Matriz de confusión y reporte por clase\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Obtener etiquetas verdaderas y predichas\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Classification report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "# Mostrar matriz como imagen\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "plt.yticks(range(len(class_names)), class_names)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fa4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def predict_image(model, img_path, class_names, image_size=(128,128)):\n",
    "    img = image.load_img(img_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x.astype('float32') / 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)[0]\n",
    "    top_idx = np.argmax(preds)\n",
    "    return top_idx, preds[top_idx], preds\n",
    "\n",
    "# Uso:\n",
    "# idx, prob, all_probs = predict_image(model, \"ruta/a/imagen.jpg\", class_names)\n",
    "# print(class_names[idx], prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"flower_model.h5\")\n",
    "# cargar\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model(\"flower_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"flower_savedmodel\")   # carpeta con formato SavedModel\n",
    "# cargar\n",
    "model3 = tf.keras.models.load_model(\"flower_savedmodel\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
